{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Data Analysis of Tech Gadgets Sales with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 files in the directory: ./data.\n",
      "Here is the list of the files read: \n",
      "['gadget-sales-april-2019.csv', 'gadget-sales-august-2019.csv', 'gadget-sales-december-2019.csv', 'gadget-sales-february-2019.csv', 'gadget-sales-january-2019.csv', 'gadget-sales-july-2019.csv', 'gadget-sales-june-2019.csv', 'gadget-sales-march-2019.csv', 'gadget-sales-may-2019.csv', 'gadget-sales-november-2019.csv', 'gadget-sales-october-2019.csv', 'gadget-sales-september-2019.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>176558</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>2</td>\n",
       "      <td>11.95</td>\n",
       "      <td>04/19/19 08:46</td>\n",
       "      <td>917 1st St, Dallas, TX 75001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>176559</td>\n",
       "      <td>Bose SoundSport Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>99.99</td>\n",
       "      <td>04/07/19 22:30</td>\n",
       "      <td>682 Chestnut St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>176560</td>\n",
       "      <td>Google Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>176560</td>\n",
       "      <td>Wired Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>11.99</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186845</th>\n",
       "      <td>186845</td>\n",
       "      <td>259353</td>\n",
       "      <td>AAA Batteries (4-pack)</td>\n",
       "      <td>3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>09/17/19 20:56</td>\n",
       "      <td>840 Highland St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186846</th>\n",
       "      <td>186846</td>\n",
       "      <td>259354</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>09/01/19 16:00</td>\n",
       "      <td>216 Dogwood St, San Francisco, CA 94016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186847</th>\n",
       "      <td>186847</td>\n",
       "      <td>259355</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>09/23/19 07:39</td>\n",
       "      <td>220 12th St, San Francisco, CA 94016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186848</th>\n",
       "      <td>186848</td>\n",
       "      <td>259356</td>\n",
       "      <td>34in Ultrawide Monitor</td>\n",
       "      <td>1</td>\n",
       "      <td>379.99</td>\n",
       "      <td>09/19/19 17:30</td>\n",
       "      <td>511 Forest St, San Francisco, CA 94016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186849</th>\n",
       "      <td>186849</td>\n",
       "      <td>259357</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>1</td>\n",
       "      <td>11.95</td>\n",
       "      <td>09/30/19 00:18</td>\n",
       "      <td>250 Meadow St, San Francisco, CA 94016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186850 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index Order ID                     Product Quantity Ordered  \\\n",
       "0            0   176558        USB-C Charging Cable                2   \n",
       "1            1      NaN                         NaN              NaN   \n",
       "2            2   176559  Bose SoundSport Headphones                1   \n",
       "3            3   176560                Google Phone                1   \n",
       "4            4   176560            Wired Headphones                1   \n",
       "...        ...      ...                         ...              ...   \n",
       "186845  186845   259353      AAA Batteries (4-pack)                3   \n",
       "186846  186846   259354                      iPhone                1   \n",
       "186847  186847   259355                      iPhone                1   \n",
       "186848  186848   259356      34in Ultrawide Monitor                1   \n",
       "186849  186849   259357        USB-C Charging Cable                1   \n",
       "\n",
       "       Price Each      Order Date                         Purchase Address  \n",
       "0           11.95  04/19/19 08:46             917 1st St, Dallas, TX 75001  \n",
       "1             NaN             NaN                                      NaN  \n",
       "2           99.99  04/07/19 22:30        682 Chestnut St, Boston, MA 02215  \n",
       "3             600  04/12/19 14:38     669 Spruce St, Los Angeles, CA 90001  \n",
       "4           11.99  04/12/19 14:38     669 Spruce St, Los Angeles, CA 90001  \n",
       "...           ...             ...                                      ...  \n",
       "186845       2.99  09/17/19 20:56   840 Highland St, Los Angeles, CA 90001  \n",
       "186846        700  09/01/19 16:00  216 Dogwood St, San Francisco, CA 94016  \n",
       "186847        700  09/23/19 07:39     220 12th St, San Francisco, CA 94016  \n",
       "186848     379.99  09/19/19 17:30   511 Forest St, San Francisco, CA 94016  \n",
       "186849      11.95  09/30/19 00:18   250 Meadow St, San Francisco, CA 94016  \n",
       "\n",
       "[186850 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the list of all files in the directory\n",
    "file_path_data = \"./data\"\n",
    "files = [file for file in os.listdir(file_path_data) if not file.startswith('.')] \n",
    "print(f\"There are {len(files)} files in the directory: {file_path_data}.\")\n",
    "print(f\"Here is the list of the files read: \\n{files}\")\n",
    "\n",
    "df_all_months = pd.DataFrame()\n",
    "\n",
    "## Combine data files\n",
    "for file in files:\n",
    "\t## Current spreadsheet\n",
    "\tcurrent_file = f\"{file_path_data}/{file}\"\n",
    "\ttry: \n",
    "\t\tdf_month = pd.read_csv(current_file)\n",
    "\texcept: \n",
    "\t\tprint(f\"An error occurred while reading the file: {current_file}\")\n",
    "\t\tsys.exit(1)\n",
    "\t## Concatenate Pandas DataFrame along the index axis \n",
    "\tdf_all_months = pd.concat([df_all_months, df_month])\n",
    "\n",
    "## Output the combined data frames to 1 file\n",
    "filename_output = \"all-gadget-sales-2019.csv\"\n",
    "file_path_output = f\"./output/{filename_output}\"\n",
    "df_all_months.to_csv(file_path_output, index=False)\n",
    "# print(df_all_months.head())\n",
    "\n",
    "## Read in the updated DataFrame\n",
    "df_all_sales = pd.read_csv(file_path_output)\n",
    "df_all_sales.reset_index()\n",
    "# print(df_all_sales.head())\n",
    "\n",
    "## Check the new DataFrame\n",
    "# print(df_all_months.equals(df_all_sales))\n",
    "# print(df_all_months.index.values)\n",
    "# print(df_all_sales.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to find out what to clean is to perform operations and get errors. Based on the errors, we decide how to go about cleaning the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Order ID Product Quantity Ordered Price Each Order Date Purchase Address\n",
      "1         NaN     NaN              NaN        NaN        NaN              NaN\n",
      "356       NaN     NaN              NaN        NaN        NaN              NaN\n",
      "735       NaN     NaN              NaN        NaN        NaN              NaN\n",
      "1433      NaN     NaN              NaN        NaN        NaN              NaN\n",
      "1553      NaN     NaN              NaN        NaN        NaN              NaN\n",
      "  Order ID                     Product Quantity Ordered Price Each  \\\n",
      "0   176558        USB-C Charging Cable                2      11.95   \n",
      "2   176559  Bose SoundSport Headphones                1      99.99   \n",
      "3   176560                Google Phone                1        600   \n",
      "4   176560            Wired Headphones                1      11.99   \n",
      "5   176561            Wired Headphones                1      11.99   \n",
      "\n",
      "       Order Date                      Purchase Address  \n",
      "0  04/19/19 08:46          917 1st St, Dallas, TX 75001  \n",
      "2  04/07/19 22:30     682 Chestnut St, Boston, MA 02215  \n",
      "3  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  \n",
      "4  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  \n",
      "5  04/30/19 09:27     333 8th St, Los Angeles, CA 90001  \n"
     ]
    }
   ],
   "source": [
    "## Find rows with all NA values\n",
    "## isna() returns a boolean DataFrame that indicates whether each element is NA\n",
    "## any(axis=1) reduces columns of the boolean DataFrame to only a boolean Series\n",
    "df_nan = df_all_sales[df_all_sales.isna().any(axis=1)]\n",
    "print(df_nan.head())\n",
    "\n",
    "## Remove rows with all NA values\n",
    "df_all_sales.dropna(how='all', inplace=True)\n",
    "print(df_all_sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we created the `Month` column, we took the first 2 letters in the `Order Date` column and converted the `Month` column to the integer type, which resulted in `ValueError`. So, we came up here to perform some data cleaning operations to get rid of the text \"Or\" in `Order Date` column before we attempt the data conversion again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_sales = df_all_sales[df_all_sales['Order Date'].str[0:2] != 'Or']\n",
    "# df_all_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make columns correct type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"Quantity Ordered\" at position 517",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Asus\\Coding\\Tools\\Anaconda\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2315\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"Quantity Ordered\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Asus\\Coding\\ttr-py-data-analysis-pandas-gadget-sales\\analyze-tech-gadgets-2019.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_all_sales[\u001b[39m'\u001b[39m\u001b[39mQuantity Ordered\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_numeric(df_all_sales[\u001b[39m'\u001b[39;49m\u001b[39mQuantity Ordered\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_all_sales[\u001b[39m'\u001b[39m\u001b[39mPrice Each\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df_all_sales[\u001b[39m'\u001b[39m\u001b[39mPrice Each\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Coding\\Tools\\Anaconda\\lib\\site-packages\\pandas\\core\\tools\\numeric.py:184\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    182\u001b[0m coerce_numeric \u001b[39m=\u001b[39m errors \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    183\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     values, _ \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmaybe_convert_numeric(\n\u001b[0;32m    185\u001b[0m         values, \u001b[39mset\u001b[39;49m(), coerce_numeric\u001b[39m=\u001b[39;49mcoerce_numeric\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    187\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Coding\\Tools\\Anaconda\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2357\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"Quantity Ordered\" at position 517"
     ]
    }
   ],
   "source": [
    "df_all_sales['Quantity Ordered'] = pd.to_numeric(df_all_sales['Quantity Ordered'])\n",
    "df_all_sales['Price Each'] = pd.to_numeric(df_all_sales['Price Each'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment data with additional columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add month column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sales['Month'] = df_all_sales['Order Date'].str[0:2]\n",
    "df_all_sales['Month'] = df_all_sales['Month'].astype('int32')\n",
    "df_all_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add month column (alternative method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sales['Month 2'] = pd.to_datetime(df_all_sales['Order Date']).dt.month\n",
    "df_all_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add city column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city(address):\n",
    "    return address.split(\",\")[1].strip(\" \")\n",
    "\n",
    "def get_state(address):\n",
    "    return address.split(\",\")[2].split(\" \")[1]\n",
    "\n",
    "df_all_sales['City'] = df_all_sales['Purchase Address'].apply(lambda x: f\"{get_city(x)}  ({get_state(x)})\")\n",
    "df_all_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: What was the best month for sales? How much was earned that month? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sales['Sales'] = df_all_sales['Quantity Ordered'].astype('int') * df_all_sales['Price Each'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sales.groupby(['Month']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "months = range(1,13)\n",
    "print(months)\n",
    "\n",
    "plt.bar(months,df_all_sales.groupby(['Month']).sum()['Sales'])\n",
    "plt.xticks(months)\n",
    "plt.ylabel('Sales in USD ($)')\n",
    "plt.xlabel('Month number')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: What city sold the most product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sales.groupby(['City']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "keys = [city for city, df in df_all_sales.groupby(['City'])]\n",
    "\n",
    "plt.bar(keys,df_all_sales.groupby(['City']).sum()['Sales'])\n",
    "plt.ylabel('Sales in USD ($)')\n",
    "plt.xlabel('Month number')\n",
    "plt.xticks(keys, rotation='vertical', size=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: What time should we display advertisements to maximize likelihood of customer's buying product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hour column\n",
    "df_all_sales['Hour'] = pd.to_datetime(df_all_sales['Order Date']).dt.hour\n",
    "df_all_sales['Minute'] = pd.to_datetime(df_all_sales['Order Date']).dt.minute\n",
    "df_all_sales['Count'] = 1\n",
    "df_all_sales.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hour'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Asus\\Coding\\ttr-py-data-analysis-pandas-gadget-sales\\analyze-tech-gadgets-2019.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m keys \u001b[39m=\u001b[39m [pair \u001b[39mfor\u001b[39;00m pair, df \u001b[39min\u001b[39;00m df_all_sales\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mHour\u001b[39;49m\u001b[39m'\u001b[39;49m])]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(keys, df_all_sales\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mHour\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mcount()[\u001b[39m'\u001b[39m\u001b[39mCount\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mxticks(keys)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Coding\\Tools\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:7706\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7701\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7703\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7704\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7705\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7706\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   7707\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   7708\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   7709\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   7710\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   7711\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   7712\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   7713\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   7714\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7715\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   7716\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   7717\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Coding\\Tools\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    883\u001b[0m         obj,\n\u001b[0;32m    884\u001b[0m         keys,\n\u001b[0;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Coding\\Tools\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Hour'"
     ]
    }
   ],
   "source": [
    "keys = [pair for pair, df in df_all_sales.groupby(['Hour'])]\n",
    "\n",
    "plt.plot(keys, df_all_sales.groupby(['Hour']).count()['Count'])\n",
    "plt.xticks(keys)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# My recommendation is slightly before 11am or 7pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: What products are most often sold together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43348194/pandas-select-rows-if-id-appear-several-time\n",
    "df = df_all_sales[df_all_sales['Order ID'].duplicated(keep=False)]\n",
    "\n",
    "# Referenced: https://stackoverflow.com/questions/27298178/concatenate-strings-from-several-rows-using-pandas-groupby\n",
    "df['Grouped'] = df.groupby('Order ID')['Product'].transform(lambda x: ','.join(x))\n",
    "df2 = df[['Order ID', 'Grouped']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced: https://stackoverflow.com/questions/52195887/counting-unique-pairs-of-numbers-into-a-python-dictionary\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "count = Counter()\n",
    "\n",
    "for row in df2['Grouped']:\n",
    "    row_list = row.split(',')\n",
    "    count.update(Counter(combinations(row_list, 2)))\n",
    "\n",
    "for key,value in count.most_common(10):\n",
    "    print(key, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What product sold the most? Why do you think it sold the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Asus\\Coding\\ttr-py-data-analysis-pandas-gadget-sales\\analyze-tech-gadgets-2019.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m quantity_ordered \u001b[39m=\u001b[39m product_group\u001b[39m.\u001b[39msum()[\u001b[39m'\u001b[39m\u001b[39mQuantity Ordered\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X50sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m keys \u001b[39m=\u001b[39m [pair \u001b[39mfor\u001b[39;00m pair, df \u001b[39min\u001b[39;00m product_group]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mbar(keys, quantity_ordered)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mxticks(keys, rotation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Asus/Coding/ttr-py-data-analysis-pandas-gadget-sales/analyze-tech-gadgets-2019.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "product_group = df_all_sales.groupby('Product')\n",
    "quantity_ordered = product_group.sum()['Quantity Ordered']\n",
    "\n",
    "keys = [pair for pair, df in product_group]\n",
    "plt.bar(keys, quantity_ordered)\n",
    "plt.xticks(keys, rotation='vertical', size=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced: https://stackoverflow.com/questions/14762181/adding-a-y-axis-label-to-secondary-y-axis-in-matplotlib\n",
    "\n",
    "prices = df_all_sales.groupby('Product').mean()['Price Each']\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.bar(keys, quantity_ordered, color='g')\n",
    "ax2.plot(keys, prices, color='b')\n",
    "\n",
    "ax1.set_xlabel('Product Name')\n",
    "ax1.set_ylabel('Quantity Ordered', color='g')\n",
    "ax2.set_ylabel('Price ($)', color='b')\n",
    "ax1.set_xticklabels(keys, rotation='vertical', size=8)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2011e8f1b66e4ca782a16183c079a9a8ceaa771eb94b3143f514bb5560527e59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
